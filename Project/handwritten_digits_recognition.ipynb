{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "73d88830",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import torch\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.transforms import ToTensor\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#GPU\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "tf = transforms.Compose([\n",
    "    transforms.Grayscale(num_output_channels=1),  \n",
    "    transforms.Resize((28, 28)),                  \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.1307,), (0.3081,))    \n",
    "])\n",
    "\n",
    "loaders = {\n",
    "    'train': DataLoader(\n",
    "        datasets.ImageFolder(\n",
    "            r'C:\\Users\\ire0349s\\Documents\\GitHub\\MNIST-Handwritten-Digits\\Dataset\\train',\n",
    "            transform=tf\n",
    "        ),\n",
    "        batch_size=100,\n",
    "        shuffle=True,\n",
    "        num_workers=0 \n",
    "    ),\n",
    "    'test': DataLoader(\n",
    "        datasets.ImageFolder(\n",
    "            r'C:\\Users\\ire0349s\\Documents\\GitHub\\MNIST-Handwritten-Digits\\Dataset\\test',\n",
    "            transform=tf\n",
    "        ),\n",
    "        batch_size=100,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    ),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6ac62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#CNN structure\n",
    "class CNN(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(x.size(0), -1)  \n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        logits = self.fc2(x)\n",
    "        return logits  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45bd620c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating and optimizing the model\n",
    "model = CNN().to(device)\n",
    "\n",
    "optimizer = optim.Adam(model.parameters(), lr = 0.001)\n",
    "\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "\n",
    "def train(epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(loaders['train']):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = loss_fn(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if batch_idx % 20 == 0:\n",
    "            print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(loaders[\"train\"].dataset)}({100. * batch_idx / len(loaders[\"train\"]): .0f}%)]\\t{loss.item():.6f}')\n",
    "\n",
    "def test():\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for data, target in loaders['test']:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            logits = model(data)\n",
    "            loss = loss_fn(logits, target)\n",
    "            total_loss += loss.item() * data.size(0)  \n",
    "            pred = logits.argmax(dim=1)\n",
    "            correct += (pred == target).sum().item()\n",
    "            total += data.size(0)\n",
    "    \n",
    "    avg_loss = total_loss / total\n",
    "    acc = correct / total\n",
    "    \n",
    "    print(f\"\\nTest set: Average loss: {avg_loss:.4f}, Accuracy {correct}/{total} ({100*acc:.2f}%)\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "92d05163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/53410( 0%)]\t2.316168\n",
      "Train Epoch: 1 [2000/53410( 4%)]\t1.900941\n",
      "Train Epoch: 1 [4000/53410( 7%)]\t1.165466\n",
      "Train Epoch: 1 [6000/53410( 11%)]\t0.832252\n",
      "Train Epoch: 1 [8000/53410( 15%)]\t0.787498\n",
      "Train Epoch: 1 [10000/53410( 19%)]\t0.487256\n",
      "Train Epoch: 1 [12000/53410( 22%)]\t0.686990\n",
      "Train Epoch: 1 [14000/53410( 26%)]\t0.363687\n",
      "Train Epoch: 1 [16000/53410( 30%)]\t0.466432\n",
      "Train Epoch: 1 [18000/53410( 34%)]\t0.423788\n",
      "Train Epoch: 1 [20000/53410( 37%)]\t0.440579\n",
      "Train Epoch: 1 [22000/53410( 41%)]\t0.255490\n",
      "Train Epoch: 1 [24000/53410( 45%)]\t0.245606\n",
      "Train Epoch: 1 [26000/53410( 49%)]\t0.346369\n",
      "Train Epoch: 1 [28000/53410( 52%)]\t0.360509\n",
      "Train Epoch: 1 [30000/53410( 56%)]\t0.282792\n",
      "Train Epoch: 1 [32000/53410( 60%)]\t0.301015\n",
      "Train Epoch: 1 [34000/53410( 64%)]\t0.195664\n",
      "Train Epoch: 1 [36000/53410( 67%)]\t0.241948\n",
      "Train Epoch: 1 [38000/53410( 71%)]\t0.319847\n",
      "Train Epoch: 1 [40000/53410( 75%)]\t0.221486\n",
      "Train Epoch: 1 [42000/53410( 79%)]\t0.250328\n",
      "Train Epoch: 1 [44000/53410( 82%)]\t0.199652\n",
      "Train Epoch: 1 [46000/53410( 86%)]\t0.177096\n",
      "Train Epoch: 1 [48000/53410( 90%)]\t0.270363\n",
      "Train Epoch: 1 [50000/53410( 93%)]\t0.226478\n",
      "Train Epoch: 1 [52000/53410( 97%)]\t0.259615\n",
      "\n",
      "Test set: Average loss: 1.6021, Accuracy 8760/10000 (87.60%)\n",
      "\n",
      "Train Epoch: 2 [0/53410( 0%)]\t0.284023\n",
      "Train Epoch: 2 [2000/53410( 4%)]\t0.159655\n",
      "Train Epoch: 2 [4000/53410( 7%)]\t0.147202\n",
      "Train Epoch: 2 [6000/53410( 11%)]\t0.165637\n",
      "Train Epoch: 2 [8000/53410( 15%)]\t0.361172\n",
      "Train Epoch: 2 [10000/53410( 19%)]\t0.237394\n",
      "Train Epoch: 2 [12000/53410( 22%)]\t0.205609\n",
      "Train Epoch: 2 [14000/53410( 26%)]\t0.173302\n",
      "Train Epoch: 2 [16000/53410( 30%)]\t0.183676\n",
      "Train Epoch: 2 [18000/53410( 34%)]\t0.238395\n",
      "Train Epoch: 2 [20000/53410( 37%)]\t0.241927\n",
      "Train Epoch: 2 [22000/53410( 41%)]\t0.244720\n",
      "Train Epoch: 2 [24000/53410( 45%)]\t0.194546\n",
      "Train Epoch: 2 [26000/53410( 49%)]\t0.204525\n",
      "Train Epoch: 2 [28000/53410( 52%)]\t0.155665\n",
      "Train Epoch: 2 [30000/53410( 56%)]\t0.202995\n",
      "Train Epoch: 2 [32000/53410( 60%)]\t0.217421\n",
      "Train Epoch: 2 [34000/53410( 64%)]\t0.151082\n",
      "Train Epoch: 2 [36000/53410( 67%)]\t0.263077\n",
      "Train Epoch: 2 [38000/53410( 71%)]\t0.283513\n",
      "Train Epoch: 2 [40000/53410( 75%)]\t0.207506\n",
      "Train Epoch: 2 [42000/53410( 79%)]\t0.140710\n",
      "Train Epoch: 2 [44000/53410( 82%)]\t0.166441\n",
      "Train Epoch: 2 [46000/53410( 86%)]\t0.321248\n",
      "Train Epoch: 2 [48000/53410( 90%)]\t0.273897\n",
      "Train Epoch: 2 [50000/53410( 93%)]\t0.093646\n",
      "Train Epoch: 2 [52000/53410( 97%)]\t0.174606\n",
      "\n",
      "Test set: Average loss: 1.6661, Accuracy 8833/10000 (88.33%)\n",
      "\n",
      "Train Epoch: 3 [0/53410( 0%)]\t0.244389\n",
      "Train Epoch: 3 [2000/53410( 4%)]\t0.143788\n",
      "Train Epoch: 3 [4000/53410( 7%)]\t0.107836\n",
      "Train Epoch: 3 [6000/53410( 11%)]\t0.111660\n",
      "Train Epoch: 3 [8000/53410( 15%)]\t0.195284\n",
      "Train Epoch: 3 [10000/53410( 19%)]\t0.223485\n",
      "Train Epoch: 3 [12000/53410( 22%)]\t0.096878\n",
      "Train Epoch: 3 [14000/53410( 26%)]\t0.202781\n",
      "Train Epoch: 3 [16000/53410( 30%)]\t0.202187\n",
      "Train Epoch: 3 [18000/53410( 34%)]\t0.166590\n",
      "Train Epoch: 3 [20000/53410( 37%)]\t0.311708\n",
      "Train Epoch: 3 [22000/53410( 41%)]\t0.232740\n",
      "Train Epoch: 3 [24000/53410( 45%)]\t0.211525\n",
      "Train Epoch: 3 [26000/53410( 49%)]\t0.214249\n",
      "Train Epoch: 3 [28000/53410( 52%)]\t0.093399\n",
      "Train Epoch: 3 [30000/53410( 56%)]\t0.161435\n",
      "Train Epoch: 3 [32000/53410( 60%)]\t0.188196\n",
      "Train Epoch: 3 [34000/53410( 64%)]\t0.085184\n",
      "Train Epoch: 3 [36000/53410( 67%)]\t0.138481\n",
      "Train Epoch: 3 [38000/53410( 71%)]\t0.240259\n",
      "Train Epoch: 3 [40000/53410( 75%)]\t0.115459\n",
      "Train Epoch: 3 [42000/53410( 79%)]\t0.168706\n",
      "Train Epoch: 3 [44000/53410( 82%)]\t0.154330\n",
      "Train Epoch: 3 [46000/53410( 86%)]\t0.255597\n",
      "Train Epoch: 3 [48000/53410( 90%)]\t0.144283\n",
      "Train Epoch: 3 [50000/53410( 93%)]\t0.226838\n",
      "Train Epoch: 3 [52000/53410( 97%)]\t0.078065\n",
      "\n",
      "Test set: Average loss: 1.7474, Accuracy 8857/10000 (88.57%)\n",
      "\n",
      "Train Epoch: 4 [0/53410( 0%)]\t0.152763\n",
      "Train Epoch: 4 [2000/53410( 4%)]\t0.114424\n",
      "Train Epoch: 4 [4000/53410( 7%)]\t0.109083\n",
      "Train Epoch: 4 [6000/53410( 11%)]\t0.129337\n",
      "Train Epoch: 4 [8000/53410( 15%)]\t0.138002\n",
      "Train Epoch: 4 [10000/53410( 19%)]\t0.074927\n",
      "Train Epoch: 4 [12000/53410( 22%)]\t0.101560\n",
      "Train Epoch: 4 [14000/53410( 26%)]\t0.246000\n",
      "Train Epoch: 4 [16000/53410( 30%)]\t0.130181\n",
      "Train Epoch: 4 [18000/53410( 34%)]\t0.040951\n",
      "Train Epoch: 4 [20000/53410( 37%)]\t0.232248\n",
      "Train Epoch: 4 [22000/53410( 41%)]\t0.155631\n",
      "Train Epoch: 4 [24000/53410( 45%)]\t0.106652\n",
      "Train Epoch: 4 [26000/53410( 49%)]\t0.153084\n",
      "Train Epoch: 4 [28000/53410( 52%)]\t0.053961\n",
      "Train Epoch: 4 [30000/53410( 56%)]\t0.106008\n",
      "Train Epoch: 4 [32000/53410( 60%)]\t0.160756\n",
      "Train Epoch: 4 [34000/53410( 64%)]\t0.215310\n",
      "Train Epoch: 4 [36000/53410( 67%)]\t0.111034\n",
      "Train Epoch: 4 [38000/53410( 71%)]\t0.191232\n",
      "Train Epoch: 4 [40000/53410( 75%)]\t0.293930\n",
      "Train Epoch: 4 [42000/53410( 79%)]\t0.096415\n",
      "Train Epoch: 4 [44000/53410( 82%)]\t0.187416\n",
      "Train Epoch: 4 [46000/53410( 86%)]\t0.162686\n",
      "Train Epoch: 4 [48000/53410( 90%)]\t0.198924\n",
      "Train Epoch: 4 [50000/53410( 93%)]\t0.140426\n",
      "Train Epoch: 4 [52000/53410( 97%)]\t0.174685\n",
      "\n",
      "Test set: Average loss: 2.0297, Accuracy 8866/10000 (88.66%)\n",
      "\n",
      "Train Epoch: 5 [0/53410( 0%)]\t0.075964\n",
      "Train Epoch: 5 [2000/53410( 4%)]\t0.093297\n",
      "Train Epoch: 5 [4000/53410( 7%)]\t0.152544\n",
      "Train Epoch: 5 [6000/53410( 11%)]\t0.072329\n",
      "Train Epoch: 5 [8000/53410( 15%)]\t0.257776\n",
      "Train Epoch: 5 [10000/53410( 19%)]\t0.156489\n",
      "Train Epoch: 5 [12000/53410( 22%)]\t0.202416\n",
      "Train Epoch: 5 [14000/53410( 26%)]\t0.094363\n",
      "Train Epoch: 5 [16000/53410( 30%)]\t0.161250\n",
      "Train Epoch: 5 [18000/53410( 34%)]\t0.182582\n",
      "Train Epoch: 5 [20000/53410( 37%)]\t0.122651\n",
      "Train Epoch: 5 [22000/53410( 41%)]\t0.064211\n",
      "Train Epoch: 5 [24000/53410( 45%)]\t0.148922\n",
      "Train Epoch: 5 [26000/53410( 49%)]\t0.161170\n",
      "Train Epoch: 5 [28000/53410( 52%)]\t0.073786\n",
      "Train Epoch: 5 [30000/53410( 56%)]\t0.364607\n",
      "Train Epoch: 5 [32000/53410( 60%)]\t0.095411\n",
      "Train Epoch: 5 [34000/53410( 64%)]\t0.128495\n",
      "Train Epoch: 5 [36000/53410( 67%)]\t0.161571\n",
      "Train Epoch: 5 [38000/53410( 71%)]\t0.180104\n",
      "Train Epoch: 5 [40000/53410( 75%)]\t0.128648\n",
      "Train Epoch: 5 [42000/53410( 79%)]\t0.260374\n",
      "Train Epoch: 5 [44000/53410( 82%)]\t0.126671\n",
      "Train Epoch: 5 [46000/53410( 86%)]\t0.093127\n",
      "Train Epoch: 5 [48000/53410( 90%)]\t0.154090\n",
      "Train Epoch: 5 [50000/53410( 93%)]\t0.066368\n",
      "Train Epoch: 5 [52000/53410( 97%)]\t0.099847\n",
      "\n",
      "Test set: Average loss: 2.1376, Accuracy 8881/10000 (88.81%)\n",
      "\n",
      "Train Epoch: 6 [0/53410( 0%)]\t0.194306\n",
      "Train Epoch: 6 [2000/53410( 4%)]\t0.194946\n",
      "Train Epoch: 6 [4000/53410( 7%)]\t0.067483\n",
      "Train Epoch: 6 [6000/53410( 11%)]\t0.142834\n",
      "Train Epoch: 6 [8000/53410( 15%)]\t0.082683\n",
      "Train Epoch: 6 [10000/53410( 19%)]\t0.066304\n",
      "Train Epoch: 6 [12000/53410( 22%)]\t0.119953\n",
      "Train Epoch: 6 [14000/53410( 26%)]\t0.157538\n",
      "Train Epoch: 6 [16000/53410( 30%)]\t0.082492\n",
      "Train Epoch: 6 [18000/53410( 34%)]\t0.036189\n",
      "Train Epoch: 6 [20000/53410( 37%)]\t0.077803\n",
      "Train Epoch: 6 [22000/53410( 41%)]\t0.309577\n",
      "Train Epoch: 6 [24000/53410( 45%)]\t0.131247\n",
      "Train Epoch: 6 [26000/53410( 49%)]\t0.123249\n",
      "Train Epoch: 6 [28000/53410( 52%)]\t0.195442\n",
      "Train Epoch: 6 [30000/53410( 56%)]\t0.091497\n",
      "Train Epoch: 6 [32000/53410( 60%)]\t0.095731\n",
      "Train Epoch: 6 [34000/53410( 64%)]\t0.154411\n",
      "Train Epoch: 6 [36000/53410( 67%)]\t0.077465\n",
      "Train Epoch: 6 [38000/53410( 71%)]\t0.044428\n",
      "Train Epoch: 6 [40000/53410( 75%)]\t0.104968\n",
      "Train Epoch: 6 [42000/53410( 79%)]\t0.051390\n",
      "Train Epoch: 6 [44000/53410( 82%)]\t0.134559\n",
      "Train Epoch: 6 [46000/53410( 86%)]\t0.131381\n",
      "Train Epoch: 6 [48000/53410( 90%)]\t0.232566\n",
      "Train Epoch: 6 [50000/53410( 93%)]\t0.068501\n",
      "Train Epoch: 6 [52000/53410( 97%)]\t0.322712\n",
      "\n",
      "Test set: Average loss: 2.2548, Accuracy 8878/10000 (88.78%)\n",
      "\n",
      "Train Epoch: 7 [0/53410( 0%)]\t0.175493\n",
      "Train Epoch: 7 [2000/53410( 4%)]\t0.064701\n",
      "Train Epoch: 7 [4000/53410( 7%)]\t0.146801\n",
      "Train Epoch: 7 [6000/53410( 11%)]\t0.184170\n",
      "Train Epoch: 7 [8000/53410( 15%)]\t0.058626\n",
      "Train Epoch: 7 [10000/53410( 19%)]\t0.141826\n",
      "Train Epoch: 7 [12000/53410( 22%)]\t0.347697\n",
      "Train Epoch: 7 [14000/53410( 26%)]\t0.127389\n",
      "Train Epoch: 7 [16000/53410( 30%)]\t0.155167\n",
      "Train Epoch: 7 [18000/53410( 34%)]\t0.228292\n",
      "Train Epoch: 7 [20000/53410( 37%)]\t0.111525\n",
      "Train Epoch: 7 [22000/53410( 41%)]\t0.124972\n",
      "Train Epoch: 7 [24000/53410( 45%)]\t0.136402\n",
      "Train Epoch: 7 [26000/53410( 49%)]\t0.042312\n",
      "Train Epoch: 7 [28000/53410( 52%)]\t0.109503\n",
      "Train Epoch: 7 [30000/53410( 56%)]\t0.129441\n",
      "Train Epoch: 7 [32000/53410( 60%)]\t0.177771\n",
      "Train Epoch: 7 [34000/53410( 64%)]\t0.141965\n",
      "Train Epoch: 7 [36000/53410( 67%)]\t0.139071\n",
      "Train Epoch: 7 [38000/53410( 71%)]\t0.080471\n",
      "Train Epoch: 7 [40000/53410( 75%)]\t0.200696\n",
      "Train Epoch: 7 [42000/53410( 79%)]\t0.092891\n",
      "Train Epoch: 7 [44000/53410( 82%)]\t0.118234\n",
      "Train Epoch: 7 [46000/53410( 86%)]\t0.164692\n",
      "Train Epoch: 7 [48000/53410( 90%)]\t0.082435\n",
      "Train Epoch: 7 [50000/53410( 93%)]\t0.032229\n",
      "Train Epoch: 7 [52000/53410( 97%)]\t0.150599\n",
      "\n",
      "Test set: Average loss: 2.1749, Accuracy 8889/10000 (88.89%)\n",
      "\n",
      "Train Epoch: 8 [0/53410( 0%)]\t0.077293\n",
      "Train Epoch: 8 [2000/53410( 4%)]\t0.371355\n",
      "Train Epoch: 8 [4000/53410( 7%)]\t0.191568\n",
      "Train Epoch: 8 [6000/53410( 11%)]\t0.135634\n",
      "Train Epoch: 8 [8000/53410( 15%)]\t0.087753\n",
      "Train Epoch: 8 [10000/53410( 19%)]\t0.067981\n",
      "Train Epoch: 8 [12000/53410( 22%)]\t0.061665\n",
      "Train Epoch: 8 [14000/53410( 26%)]\t0.160683\n",
      "Train Epoch: 8 [16000/53410( 30%)]\t0.105928\n",
      "Train Epoch: 8 [18000/53410( 34%)]\t0.197213\n",
      "Train Epoch: 8 [20000/53410( 37%)]\t0.086743\n",
      "Train Epoch: 8 [22000/53410( 41%)]\t0.136130\n",
      "Train Epoch: 8 [24000/53410( 45%)]\t0.119261\n",
      "Train Epoch: 8 [26000/53410( 49%)]\t0.146944\n",
      "Train Epoch: 8 [28000/53410( 52%)]\t0.142065\n",
      "Train Epoch: 8 [30000/53410( 56%)]\t0.228431\n",
      "Train Epoch: 8 [32000/53410( 60%)]\t0.096606\n",
      "Train Epoch: 8 [34000/53410( 64%)]\t0.049834\n",
      "Train Epoch: 8 [36000/53410( 67%)]\t0.112720\n",
      "Train Epoch: 8 [38000/53410( 71%)]\t0.051583\n",
      "Train Epoch: 8 [40000/53410( 75%)]\t0.199694\n",
      "Train Epoch: 8 [42000/53410( 79%)]\t0.206695\n",
      "Train Epoch: 8 [44000/53410( 82%)]\t0.154813\n",
      "Train Epoch: 8 [46000/53410( 86%)]\t0.207071\n",
      "Train Epoch: 8 [48000/53410( 90%)]\t0.122832\n",
      "Train Epoch: 8 [50000/53410( 93%)]\t0.097657\n",
      "Train Epoch: 8 [52000/53410( 97%)]\t0.142699\n",
      "\n",
      "Test set: Average loss: 2.3170, Accuracy 8899/10000 (88.99%)\n",
      "\n",
      "Train Epoch: 9 [0/53410( 0%)]\t0.114579\n",
      "Train Epoch: 9 [2000/53410( 4%)]\t0.068103\n",
      "Train Epoch: 9 [4000/53410( 7%)]\t0.113323\n",
      "Train Epoch: 9 [6000/53410( 11%)]\t0.037046\n",
      "Train Epoch: 9 [8000/53410( 15%)]\t0.126406\n",
      "Train Epoch: 9 [10000/53410( 19%)]\t0.065733\n",
      "Train Epoch: 9 [12000/53410( 22%)]\t0.050610\n",
      "Train Epoch: 9 [14000/53410( 26%)]\t0.060606\n",
      "Train Epoch: 9 [16000/53410( 30%)]\t0.272569\n",
      "Train Epoch: 9 [18000/53410( 34%)]\t0.168038\n",
      "Train Epoch: 9 [20000/53410( 37%)]\t0.135028\n",
      "Train Epoch: 9 [22000/53410( 41%)]\t0.183293\n",
      "Train Epoch: 9 [24000/53410( 45%)]\t0.102806\n",
      "Train Epoch: 9 [26000/53410( 49%)]\t0.224074\n",
      "Train Epoch: 9 [28000/53410( 52%)]\t0.177994\n",
      "Train Epoch: 9 [30000/53410( 56%)]\t0.062446\n",
      "Train Epoch: 9 [32000/53410( 60%)]\t0.113929\n",
      "Train Epoch: 9 [34000/53410( 64%)]\t0.113268\n",
      "Train Epoch: 9 [36000/53410( 67%)]\t0.121085\n",
      "Train Epoch: 9 [38000/53410( 71%)]\t0.120676\n",
      "Train Epoch: 9 [40000/53410( 75%)]\t0.162734\n",
      "Train Epoch: 9 [42000/53410( 79%)]\t0.159180\n",
      "Train Epoch: 9 [44000/53410( 82%)]\t0.063199\n",
      "Train Epoch: 9 [46000/53410( 86%)]\t0.127886\n",
      "Train Epoch: 9 [48000/53410( 90%)]\t0.094231\n",
      "Train Epoch: 9 [50000/53410( 93%)]\t0.120529\n",
      "Train Epoch: 9 [52000/53410( 97%)]\t0.124348\n",
      "\n",
      "Test set: Average loss: 2.1732, Accuracy 8903/10000 (89.03%)\n",
      "\n",
      "Train Epoch: 10 [0/53410( 0%)]\t0.185530\n",
      "Train Epoch: 10 [2000/53410( 4%)]\t0.268184\n",
      "Train Epoch: 10 [4000/53410( 7%)]\t0.103530\n",
      "Train Epoch: 10 [6000/53410( 11%)]\t0.046755\n",
      "Train Epoch: 10 [8000/53410( 15%)]\t0.093051\n",
      "Train Epoch: 10 [10000/53410( 19%)]\t0.101340\n",
      "Train Epoch: 10 [12000/53410( 22%)]\t0.053126\n",
      "Train Epoch: 10 [14000/53410( 26%)]\t0.069165\n",
      "Train Epoch: 10 [16000/53410( 30%)]\t0.048351\n",
      "Train Epoch: 10 [18000/53410( 34%)]\t0.097477\n",
      "Train Epoch: 10 [20000/53410( 37%)]\t0.080385\n",
      "Train Epoch: 10 [22000/53410( 41%)]\t0.126479\n",
      "Train Epoch: 10 [24000/53410( 45%)]\t0.189981\n",
      "Train Epoch: 10 [26000/53410( 49%)]\t0.086246\n",
      "Train Epoch: 10 [28000/53410( 52%)]\t0.100964\n",
      "Train Epoch: 10 [30000/53410( 56%)]\t0.043842\n",
      "Train Epoch: 10 [32000/53410( 60%)]\t0.126643\n",
      "Train Epoch: 10 [34000/53410( 64%)]\t0.081108\n",
      "Train Epoch: 10 [36000/53410( 67%)]\t0.068220\n",
      "Train Epoch: 10 [38000/53410( 71%)]\t0.125203\n",
      "Train Epoch: 10 [40000/53410( 75%)]\t0.117014\n",
      "Train Epoch: 10 [42000/53410( 79%)]\t0.095701\n",
      "Train Epoch: 10 [44000/53410( 82%)]\t0.200369\n",
      "Train Epoch: 10 [46000/53410( 86%)]\t0.070653\n",
      "Train Epoch: 10 [48000/53410( 90%)]\t0.114317\n",
      "Train Epoch: 10 [50000/53410( 93%)]\t0.129471\n",
      "Train Epoch: 10 [52000/53410( 97%)]\t0.038902\n",
      "\n",
      "Test set: Average loss: 2.3614, Accuracy 8920/10000 (89.20%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 11):\n",
    "    train(epoch)\n",
    "    test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "d8149eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted: 1, Actual: 1\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision.transforms.functional import to_pil_image\n",
    "\n",
    "# Switch model to eval mode\n",
    "model.eval()\n",
    "\n",
    "# Pick a random sample from the test dataset\n",
    "idx = random.randrange(len(loaders['test'].dataset))\n",
    "img, label = loaders['test'].dataset[idx]\n",
    "\n",
    "# Unnormalize (reverse MNIST normalization)\n",
    "unnorm = img * 0.3081 + 0.1307\n",
    "\n",
    "# Plot image\n",
    "plt.imshow(to_pil_image(unnorm))\n",
    "plt.axis('off')\n",
    "plt.title(\"Random Test Sample\")\n",
    "plt.show()\n",
    "\n",
    "# Run through model\n",
    "with torch.no_grad():\n",
    "    logits = model(img.unsqueeze(0).to(device))\n",
    "    pred = logits.argmax(1).item()\n",
    "\n",
    "# Get class names from dataset\n",
    "class_names = loaders['test'].dataset.classes\n",
    "print(f\"Predicted: {class_names[pred]}, Actual: {class_names[label]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
